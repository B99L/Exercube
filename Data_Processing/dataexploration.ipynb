{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (6, 3, 28, 360000)\n",
      "Data Type: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the .npy file\n",
    "data = np.load(\"C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit/pats.npy\")\n",
    "\n",
    "# Get the shape and data type of the array\n",
    "print(f'Shape: {data.shape}')\n",
    "print(f'Data Type: {data.dtype}')\n",
    "# Otherwise, you might want to look at just the first few rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subject_number' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [3], line 21\u001B[0m\n\u001B[0;32m     19\u001B[0m subject_data \u001B[38;5;241m=\u001B[39m data[i]\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m#subject_number = subject_number_mapping[i]  # Get the new subject number from the mapping\u001B[39;00m\n\u001B[1;32m---> 21\u001B[0m filename \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msub\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[43msubject_number\u001B[49m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.npy\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     22\u001B[0m np\u001B[38;5;241m.\u001B[39msave(filename, subject_data)\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSaved \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilename\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'subject_number' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the .npy file\n",
    "data = np.load(\"C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit/pats.npy\")\n",
    "\n",
    "# Get the number of subjects from the shape of the array\n",
    "num_subjects = data.shape[0]\n",
    "\n",
    "# Define a mapping from old subject numbers to new subject numbers\n",
    "subject_number_mapping = {\n",
    "    0: '01', 1: '02', 2: '03', 3: '04', 4: '05',\n",
    "    5: '06', 6: '07', 7: '08', 8: '09', 9: '10',\n",
    "    10: '11', 11: '12', 12: '13', 13: '14', 14: '16',\n",
    "    15: '18', 16: '19', 17: '20', 18: '21', 19: '22'\n",
    "}\n",
    "\n",
    "# Iterate through each subject and save their data to a new .npy file\n",
    "for i in range(num_subjects):\n",
    "    subject_data = data[i]\n",
    "    #subject_number = subject_number_mapping[i]  # Get the new subject number from the mapping\n",
    "    filename = f'sub{subject_number}.npy'\n",
    "    np.save(filename, subject_data)\n",
    "    print(f'Saved {filename}')\n",
    "\n",
    "print(\"All subjects' data have been saved to individual .npy files.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pat_01.npy\n",
      "Saved pat_02.npy\n",
      "Saved pat_04.npy\n",
      "Saved pat_05.npy\n",
      "Saved pat_06.npy\n",
      "Saved pat_07.npy\n",
      "All subjects' data have been saved to individual .npy files.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the .npy file\n",
    "data = np.load(\"C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit/pats.npy\")\n",
    "\n",
    "# Get the number of subjects from the shape of the array\n",
    "num_subjects = data.shape[0]\n",
    "\n",
    "# Start with patient 01\n",
    "pat_num = 1\n",
    "\n",
    "# Iterate through each subject and save their data to a new .npy file\n",
    "for i in range(num_subjects):\n",
    "    # Skip patient 03\n",
    "    if pat_num == 3:\n",
    "        pat_num += 1\n",
    "\n",
    "    subject_data = data[i]\n",
    "    filename = f'pat_{pat_num:02}.npy'  # Format the patient number with two digits\n",
    "    np.save(filename, subject_data)\n",
    "    print(f'Saved {filename}')\n",
    "\n",
    "    # Increment patient number\n",
    "    pat_num += 1\n",
    "\n",
    "    # Stop if we reach patient 07\n",
    "    if pat_num > 7:\n",
    "        break\n",
    "\n",
    "print(\"All subjects' data have been saved to individual .npy files.\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3, 28, 360000)\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"sub01.npy\")\n",
    "print(f'Shape: {data.shape}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating individual csv files annotated with the timestamps for all frames"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub01_data.csv.\n",
      "Saved C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub02_data.csv.\n",
      "Saved C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub03_data.csv.\n",
      "Saved C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub04_data.csv.\n",
      "Saved C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub05_data.csv.\n",
      "Saved C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub06_data.csv.\n",
      "Saved C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub07_data.csv.\n",
      "Saved C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub08_data.csv.\n",
      "Saved C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub09_data.csv.\n",
      "Saved C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub10_data.csv.\n",
      "Saved C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub11_data.csv.\n",
      "Saved C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub12_data.csv.\n",
      "Saved C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub13_data.csv.\n",
      "Saved C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub14_data.csv.\n",
      "Saved C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub16_data.csv.\n",
      "Saved C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub18_data.csv.\n",
      "Saved C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub19_data.csv.\n",
      "Saved C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub20_data.csv.\n",
      "Saved C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub21_data.csv.\n",
      "Saved C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub22_data.csv.\n",
      "Finished processing all .npy and .log files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "def getMarkerOrder():\n",
    "    return np.array([\n",
    "        'LPPI', 'RPPI', 'LPPS', 'RPPS', 'LThiUpLat', 'LThiUpMed', 'LThiLoLat',\n",
    "        'LThiLoMed', 'LShaUpLat', 'LShaUpMed', 'LShaLoLat', 'LShaLoMed',\n",
    "        'RThiUpLat', 'RThiUpMed', 'RThiLoLat', 'RThiLoMed', 'RShaUpLat',\n",
    "        'RShaUpMed', 'RShaLoLat', 'RShaLoMed', 'LHeePoDis', 'LHeePoPro',\n",
    "        'LHeeLaTer', 'LHeeMeDia', 'RHeePoDis', 'RHeePoPro', 'RHeeLaTer',\n",
    "        'RHeeMeDia'\n",
    "    ])\n",
    "\n",
    "# Define the directories\n",
    "log_files_dir = 'C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit/LogFiles'\n",
    "npy_files_dir = 'C:/Users/nevio/OneDrive - ZHAW/Dokumente/GitHub/PA-Exercube-ZHAW'\n",
    "output_dir = 'C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate through all the .log files in the LogFiles directory\n",
    "for log_file in os.listdir(log_files_dir):\n",
    "    if log_file.startswith('sub') and log_file.endswith('_log_file.log'):\n",
    "        # Extract the subject number from the log file name\n",
    "        subject_number = log_file[3:5]\n",
    "        # Construct the path to the corresponding .npy file\n",
    "        npy_file_path = os.path.join(npy_files_dir, f'sub{subject_number}.npy')\n",
    "\n",
    "        # Check if the corresponding .npy file exists\n",
    "        if os.path.exists(npy_file_path):\n",
    "            # Load the .npy file\n",
    "            data = np.load(npy_file_path)\n",
    "\n",
    "            # Read the log file and extract the timestamp\n",
    "            with open(os.path.join(log_files_dir, log_file), 'r') as f:\n",
    "                log_content = f.read()\n",
    "            try:\n",
    "                timestamp_str = log_content.split('Player crossed finish line! Race ends...')[0].rsplit('[', 1)[-1].split(']')[0]\n",
    "                # Convert the timestamp string to datetime object and remove the timezone\n",
    "                timestamp = pd.to_datetime(timestamp_str).tz_localize(None)\n",
    "            except IndexError:\n",
    "                print(f'Warning: Timestamp not found in {log_file}')\n",
    "                continue  # Skip to the next iteration if the timestamp is not found\n",
    "\n",
    "            # Subtract 25 minutes and add 1 second to get the start time\n",
    "            start_timestamp = timestamp - timedelta(minutes=25, seconds=-1)\n",
    "\n",
    "            # Create an array of timestamps for each frame\n",
    "            num_frames = data.shape[2]\n",
    "            seconds = np.arange(num_frames // 240)  # Each second has 240 frames\n",
    "            timestamp_array = np.array([start_timestamp + timedelta(seconds=int(s)) for s in seconds for _ in range(240)])\n",
    "\n",
    "            # Get the marker order\n",
    "            marker_order = getMarkerOrder()\n",
    "\n",
    "            # Create column names based on the marker order\n",
    "            columns = [f'{marker}_Axis{axis}' for marker in marker_order for axis in ['X', 'Y', 'Z']]\n",
    "\n",
    "            # Reshape the data array to 2D (flattening the axis and marker dimensions)\n",
    "            data_reshaped = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "\n",
    "            # Transpose the reshaped data array so that each column represents a frame\n",
    "            data_transposed = data_reshaped.T\n",
    "\n",
    "            # Create a DataFrame\n",
    "            df = pd.DataFrame(data_transposed, columns=columns)\n",
    "\n",
    "            # Add the timestamps as a new column\n",
    "            df['Timestamp'] = timestamp_array\n",
    "\n",
    "            # Save the DataFrame to a new .csv file\n",
    "            output_file_path = os.path.join(output_dir, f'sub{subject_number}_data.csv')\n",
    "            df.to_csv(output_file_path, index=False)\n",
    "            print(f'Saved {output_file_path}.')\n",
    "        else:\n",
    "            print(f'Warning: No corresponding .npy file found for {log_file}')\n",
    "\n",
    "print('Finished processing all .npy and .log files.')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\pat01_data.csv.\n",
      "Saved C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\pat02_data.csv.\n",
      "Saved C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\pat04_data.csv.\n",
      "Saved C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\pat05_data.csv.\n",
      "Saved C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\pat06_data.csv.\n",
      "Saved C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\pat07_data.csv.\n",
      "Finished processing all .npy and .log files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "def getMarkerOrder():\n",
    "    return np.array([\n",
    "        'LPPI', 'RPPI', 'LPPS', 'RPPS', 'LThiUpLat', 'LThiUpMed', 'LThiLoLat',\n",
    "        'LThiLoMed', 'LShaUpLat', 'LShaUpMed', 'LShaLoLat', 'LShaLoMed',\n",
    "        'RThiUpLat', 'RThiUpMed', 'RThiLoLat', 'RThiLoMed', 'RShaUpLat',\n",
    "        'RShaUpMed', 'RShaLoLat', 'RShaLoMed', 'LHeePoDis', 'LHeePoPro',\n",
    "        'LHeeLaTer', 'LHeeMeDia', 'RHeePoDis', 'RHeePoPro', 'RHeeLaTer',\n",
    "        'RHeeMeDia'\n",
    "    ])\n",
    "\n",
    "# Define the directories\n",
    "log_files_dir = 'C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit/LogFiles'\n",
    "npy_files_dir = 'C:/Users/nevio/OneDrive - ZHAW/Dokumente/GitHub/PA-Exercube-ZHAW'\n",
    "output_dir = 'C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate through all the .log files in the LogFiles directory\n",
    "for log_file in os.listdir(log_files_dir):\n",
    "    if log_file.startswith('pat') and log_file.endswith('_log_file.log'):\n",
    "        # Extract the patient number from the log file name\n",
    "        patient_number = log_file[3:5]\n",
    "        # Construct the path to the corresponding .npy file\n",
    "        npy_file_path = os.path.join(npy_files_dir, f'pat_{patient_number}.npy')\n",
    "\n",
    "        # Check if the corresponding .npy file exists\n",
    "        if os.path.exists(npy_file_path):\n",
    "            # Load the .npy file\n",
    "            data = np.load(npy_file_path)\n",
    "\n",
    "            # Read the log file and extract the timestamp\n",
    "            with open(os.path.join(log_files_dir, log_file), 'r') as f:\n",
    "                log_content = f.read()\n",
    "            try:\n",
    "                timestamp_str = log_content.split('Player crossed finish line! Race ends...')[0].rsplit('[', 1)[-1].split(']')[0]\n",
    "                # Convert the timestamp string to datetime object and remove the timezone\n",
    "                timestamp = pd.to_datetime(timestamp_str).tz_localize(None)\n",
    "            except IndexError:\n",
    "                print(f'Warning: Timestamp not found in {log_file}')\n",
    "                continue  # Skip to the next iteration if the timestamp is not found\n",
    "\n",
    "            # Subtract 25 minutes and add 1 second to get the start time\n",
    "            start_timestamp = timestamp - timedelta(minutes=25, seconds=-1)\n",
    "\n",
    "            # Create an array of timestamps for each frame\n",
    "            num_frames = data.shape[2]\n",
    "            seconds = np.arange(num_frames // 240)  # Each second has 240 frames\n",
    "            timestamp_array = np.array([start_timestamp + timedelta(seconds=int(s)) for s in seconds for _ in range(240)])\n",
    "\n",
    "            # Get the marker order\n",
    "            marker_order = getMarkerOrder()\n",
    "\n",
    "            # Create column names based on the marker order\n",
    "            columns = [f'{marker}_Axis{axis}' for marker in marker_order for axis in ['X', 'Y', 'Z']]\n",
    "\n",
    "            # Reshape the data array to 2D (flattening the axis and marker dimensions)\n",
    "            data_reshaped = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "\n",
    "            # Transpose the reshaped data array so that each column represents a frame\n",
    "            data_transposed = data_reshaped.T\n",
    "\n",
    "            # Create a DataFrame\n",
    "            df = pd.DataFrame(data_transposed, columns=columns)\n",
    "\n",
    "            # Add the timestamps as a new column\n",
    "            df['Timestamp'] = timestamp_array\n",
    "\n",
    "            # Save the DataFrame to a new .csv file\n",
    "            output_file_path = os.path.join(output_dir, f'pat{patient_number}_data.csv')\n",
    "            df.to_csv(output_file_path, index=False)\n",
    "            print(f'Saved {output_file_path}.')\n",
    "        else:\n",
    "            print(f'Warning: No corresponding .npy file found for {log_file}')\n",
    "\n",
    "print('Finished processing all .npy and .log files.')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Checking whether the timestamp creation worked as intended\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five entries:\n",
      "0    2021-11-16 11:06:46\n",
      "1    2021-11-16 11:06:46\n",
      "2    2021-11-16 11:06:46\n",
      "3    2021-11-16 11:06:46\n",
      "4    2021-11-16 11:06:46\n",
      "Name: Timestamp, dtype: object\n",
      "\n",
      "Last five entries:\n",
      "359995    2021-11-16 11:31:45\n",
      "359996    2021-11-16 11:31:45\n",
      "359997    2021-11-16 11:31:45\n",
      "359998    2021-11-16 11:31:45\n",
      "359999    2021-11-16 11:31:45\n",
      "Name: Timestamp, dtype: object\n",
      "\n",
      "First five unique timestamps:\n",
      "['2021-11-16 11:06:46' '2021-11-16 11:06:47' '2021-11-16 11:06:48'\n",
      " '2021-11-16 11:06:49' '2021-11-16 11:06:50']\n",
      "\n",
      "Last five unique timestamps:\n",
      "['2021-11-16 11:31:41' '2021-11-16 11:31:42' '2021-11-16 11:31:43'\n",
      " '2021-11-16 11:31:44' '2021-11-16 11:31:45']\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the DataFrame\n",
    "df = pd.read_csv(\"C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit/sub01_data.csv\")\n",
    "\n",
    "# Get the first and last five entries in the dataframe\n",
    "first_five_entries = df['Timestamp'].head(5)\n",
    "last_five_entries = df['Timestamp'].tail(5)\n",
    "\n",
    "# Get the unique timestamps, then take the first and last five of these\n",
    "unique_timestamps = df['Timestamp'].unique()\n",
    "first_five_unique = unique_timestamps[:5]\n",
    "last_five_unique = unique_timestamps[-5:]\n",
    "timestamp_1500 = df['Timestamp'].iloc[1499]\n",
    "\n",
    "# Print the results\n",
    "print(\"First five entries:\")\n",
    "print(first_five_entries)\n",
    "print(\"\\nLast five entries:\")\n",
    "print(last_five_entries)\n",
    "print(\"\\nFirst five unique timestamps:\")\n",
    "print(first_five_unique)\n",
    "print(\"\\nLast five unique timestamps:\")\n",
    "print(last_five_unique)\n",
    "print(len(unique_timestamps))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Adding the exercises to the dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file not found for subject pat01: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\pat01_data.csv\n",
      "CSV file not found for subject pat02: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\pat02_data.csv\n",
      "CSV file not found for subject pat04: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\pat04_data.csv\n",
      "CSV file not found for subject pat05: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\pat05_data.csv\n",
      "CSV file not found for subject pat06: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\pat06_data.csv\n",
      "CSV file not found for subject pat07: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\pat07_data.csv\n",
      "Updated file for subject sub01 saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub01_updated_data.csv\n",
      "Updated file for subject sub02 saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub02_updated_data.csv\n",
      "Updated file for subject sub03 saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub03_updated_data.csv\n",
      "Updated file for subject sub04 saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub04_updated_data.csv\n",
      "Updated file for subject sub05 saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub05_updated_data.csv\n",
      "Updated file for subject sub06 saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub06_updated_data.csv\n",
      "Updated file for subject sub07 saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub07_updated_data.csv\n",
      "Updated file for subject sub08 saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub08_updated_data.csv\n",
      "Updated file for subject sub09 saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub09_updated_data.csv\n",
      "Updated file for subject sub10 saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub10_updated_data.csv\n",
      "Updated file for subject sub11 saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub11_updated_data.csv\n",
      "Updated file for subject sub12 saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub12_updated_data.csv\n",
      "Updated file for subject sub13 saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub13_updated_data.csv\n",
      "Updated file for subject sub14 saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub14_updated_data.csv\n",
      "Updated file for subject sub16 saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub16_updated_data.csv\n",
      "Updated file for subject sub18 saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub18_updated_data.csv\n",
      "Updated file for subject sub19 saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub19_updated_data.csv\n",
      "Updated file for subject sub20 saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub20_updated_data.csv\n",
      "Updated file for subject sub21 saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub21_updated_data.csv\n",
      "Updated file for subject sub22 saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\sub22_updated_data.csv\n",
      "Finished processing all log and CSV files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the directories\n",
    "log_files_dir = 'C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit/LogFiles'\n",
    "csv_files_dir = 'C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit'\n",
    "output_dir = 'C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit'\n",
    "\n",
    "# Function to parse the timestamp and remove the timezone\n",
    "def parse_timestamp(timestr):\n",
    "    return datetime.strptime(timestr.split('+')[0].strip(), '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Iterate through all the log files in the directory\n",
    "for log_file in os.listdir(log_files_dir):\n",
    "    if log_file.endswith('.log'):\n",
    "        # Extract the subject number from the log file name\n",
    "        subject_number = log_file.split('_')[0]\n",
    "\n",
    "        # Paths for the corresponding CSV file\n",
    "        csv_file_path = os.path.join(csv_files_dir, f'{subject_number}_data.csv')\n",
    "\n",
    "        # Check if the corresponding CSV file exists\n",
    "        if os.path.exists(csv_file_path):\n",
    "            exercise_mapping = {}\n",
    "\n",
    "            with open(os.path.join(log_files_dir, log_file), 'r', encoding='utf-8') as file:\n",
    "                for line in file:\n",
    "                    if \"Exercise correct:\" in line:\n",
    "                        parts = line.split(']')\n",
    "                        timestamp_str = parts[0].strip('[')\n",
    "                        exercise_name = parts[1].split(\"'\")[1]  # Extracting the exercise name\n",
    "                        timestamp = parse_timestamp(timestamp_str)\n",
    "                        exercise_mapping[timestamp] = exercise_name\n",
    "\n",
    "            # Load the CSV data\n",
    "            csv_data = pd.read_csv(csv_file_path)\n",
    "            csv_data['Timestamp'] = pd.to_datetime(csv_data['Timestamp'])\n",
    "\n",
    "            # Add an 'Exercise' column if it doesn't exist\n",
    "            if 'Exercise' not in csv_data.columns:\n",
    "                csv_data['Exercise'] = None\n",
    "\n",
    "            for exercise_timestamp, exercise in exercise_mapping.items():\n",
    "                # Find the rows with the matching timestamp and annotate them\n",
    "                matching_indices = csv_data[csv_data['Timestamp'] == exercise_timestamp].index\n",
    "                if not matching_indices.empty:\n",
    "                    csv_data.loc[matching_indices, 'Exercise'] = exercise\n",
    "\n",
    "            # Save the updated data\n",
    "            updated_csv_file_path = os.path.join(output_dir, f'{subject_number}_updated_data.csv')\n",
    "            csv_data.to_csv(updated_csv_file_path, index=False)\n",
    "            print(f'Updated file for subject {subject_number} saved: {updated_csv_file_path}')\n",
    "        else:\n",
    "            print(f\"CSV file not found for subject {subject_number}: {csv_file_path}\")\n",
    "\n",
    "print('Finished processing all log and CSV files.')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated file for patient pat01 saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\pat01_updated_data.csv\n",
      "Updated file for patient pat02 saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\pat02_updated_data.csv\n",
      "Updated file for patient pat04 saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\pat04_updated_data.csv\n",
      "Updated file for patient pat05 saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\pat05_updated_data.csv\n",
      "Updated file for patient pat06 saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\pat06_updated_data.csv\n",
      "Updated file for patient pat07 saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\pat07_updated_data.csv\n",
      "Finished processing all log and CSV files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the directories\n",
    "log_files_dir = 'C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit/LogFiles'\n",
    "csv_files_dir = 'C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit'\n",
    "output_dir = 'C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit'\n",
    "\n",
    "# Function to parse the timestamp and remove the timezone\n",
    "def parse_timestamp(timestr):\n",
    "    return datetime.strptime(timestr.split('+')[0].strip(), '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Iterate through all the log files in the directory\n",
    "for log_file in os.listdir(log_files_dir):\n",
    "    if log_file.startswith('pat') and log_file.endswith('_log_file.log'):\n",
    "        # Extract the patient number from the log file name\n",
    "        patient_number = log_file.split('_')[0]\n",
    "\n",
    "        # Paths for the corresponding CSV file\n",
    "        csv_file_path = os.path.join(csv_files_dir, f'{patient_number}_data.csv')\n",
    "\n",
    "        # Check if the corresponding CSV file exists\n",
    "        if os.path.exists(csv_file_path):\n",
    "            exercise_mapping = {}\n",
    "\n",
    "            with open(os.path.join(log_files_dir, log_file), 'r', encoding='utf-8') as file:\n",
    "                for line in file:\n",
    "                    if \"Exercise correct:\" in line:\n",
    "                        parts = line.split(']')\n",
    "                        timestamp_str = parts[0].strip('[')\n",
    "                        exercise_name = parts[1].split(\"'\")[1]  # Extracting the exercise name\n",
    "                        timestamp = parse_timestamp(timestamp_str)\n",
    "                        exercise_mapping[timestamp] = exercise_name\n",
    "\n",
    "            # Load the CSV data\n",
    "            csv_data = pd.read_csv(csv_file_path)\n",
    "            csv_data['Timestamp'] = pd.to_datetime(csv_data['Timestamp'])\n",
    "\n",
    "            # Add an 'Exercise' column if it doesn't exist\n",
    "            if 'Exercise' not in csv_data.columns:\n",
    "                csv_data['Exercise'] = None\n",
    "\n",
    "            for exercise_timestamp, exercise in exercise_mapping.items():\n",
    "                # Find the rows with the matching timestamp and annotate them\n",
    "                matching_indices = csv_data[csv_data['Timestamp'] == exercise_timestamp].index\n",
    "                if not matching_indices.empty:\n",
    "                    csv_data.loc[matching_indices, 'Exercise'] = exercise\n",
    "\n",
    "            # Save the updated data\n",
    "            updated_csv_file_path = os.path.join(output_dir, f'{patient_number}_updated_data.csv')\n",
    "            csv_data.to_csv(updated_csv_file_path, index=False)\n",
    "            print(f'Updated file for patient {patient_number} saved: {updated_csv_file_path}')\n",
    "        else:\n",
    "            print(f\"CSV file not found for patient {patient_number}: {csv_file_path}\")\n",
    "\n",
    "print('Finished processing all log and CSV files.')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Checking whether the Exercises have been added"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of exercises added: 124800\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace this with the path to your CSV file\n",
    "csv_file_path = 'C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit/pat01_updated_data.csv'\n",
    "\n",
    "# Load the CSV data into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Assuming the exercises are listed in a column named 'Exercise'\n",
    "# We count the number of non-NaN (not empty) entries in the 'Exercise' column\n",
    "number_of_exercises = df['Exercise'].notna().sum()\n",
    "\n",
    "print(f'Total number of exercises added: {number_of_exercises}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the CSV file:\n",
      "['LPPI_AxisX', 'LPPI_AxisY', 'LPPI_AxisZ', 'RPPI_AxisX', 'RPPI_AxisY', 'RPPI_AxisZ', 'LPPS_AxisX', 'LPPS_AxisY', 'LPPS_AxisZ', 'RPPS_AxisX', 'RPPS_AxisY', 'RPPS_AxisZ', 'LThiUpLat_AxisX', 'LThiUpLat_AxisY', 'LThiUpLat_AxisZ', 'LThiUpMed_AxisX', 'LThiUpMed_AxisY', 'LThiUpMed_AxisZ', 'LThiLoLat_AxisX', 'LThiLoLat_AxisY', 'LThiLoLat_AxisZ', 'LThiLoMed_AxisX', 'LThiLoMed_AxisY', 'LThiLoMed_AxisZ', 'LShaUpLat_AxisX', 'LShaUpLat_AxisY', 'LShaUpLat_AxisZ', 'LShaUpMed_AxisX', 'LShaUpMed_AxisY', 'LShaUpMed_AxisZ', 'LShaLoLat_AxisX', 'LShaLoLat_AxisY', 'LShaLoLat_AxisZ', 'LShaLoMed_AxisX', 'LShaLoMed_AxisY', 'LShaLoMed_AxisZ', 'RThiUpLat_AxisX', 'RThiUpLat_AxisY', 'RThiUpLat_AxisZ', 'RThiUpMed_AxisX', 'RThiUpMed_AxisY', 'RThiUpMed_AxisZ', 'RThiLoLat_AxisX', 'RThiLoLat_AxisY', 'RThiLoLat_AxisZ', 'RThiLoMed_AxisX', 'RThiLoMed_AxisY', 'RThiLoMed_AxisZ', 'RShaUpLat_AxisX', 'RShaUpLat_AxisY', 'RShaUpLat_AxisZ', 'RShaUpMed_AxisX', 'RShaUpMed_AxisY', 'RShaUpMed_AxisZ', 'RShaLoLat_AxisX', 'RShaLoLat_AxisY', 'RShaLoLat_AxisZ', 'RShaLoMed_AxisX', 'RShaLoMed_AxisY', 'RShaLoMed_AxisZ', 'LHeePoDis_AxisX', 'LHeePoDis_AxisY', 'LHeePoDis_AxisZ', 'LHeePoPro_AxisX', 'LHeePoPro_AxisY', 'LHeePoPro_AxisZ', 'LHeeLaTer_AxisX', 'LHeeLaTer_AxisY', 'LHeeLaTer_AxisZ', 'LHeeMeDia_AxisX', 'LHeeMeDia_AxisY', 'LHeeMeDia_AxisZ', 'RHeePoDis_AxisX', 'RHeePoDis_AxisY', 'RHeePoDis_AxisZ', 'RHeePoPro_AxisX', 'RHeePoPro_AxisY', 'RHeePoPro_AxisZ', 'RHeeLaTer_AxisX', 'RHeeLaTer_AxisY', 'RHeeLaTer_AxisZ', 'RHeeMeDia_AxisX', 'RHeeMeDia_AxisY', 'RHeeMeDia_AxisZ', 'Timestamp', 'Exercise']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace this with the path to your CSV file\n",
    "csv_file_path = 'C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit/sub02_updated_data.csv'\n",
    "# Load the CSV data into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Get the list of all column names\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "# Print the list of column names\n",
    "print(\"Column names in the CSV file:\")\n",
    "print(column_names)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Removing rows where no exercises were performed and combining all csv files into a big file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV file saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directories\n",
    "csv_files_dir = 'C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit'\n",
    "output_dir = 'C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit'\n",
    "combined_csv_file_path = os.path.join(output_dir, 'combined_data.csv')\n",
    "\n",
    "# List to hold data from all files\n",
    "all_data = []\n",
    "\n",
    "# Iterate through all CSV files in the directory that end with 'updated_data.csv'\n",
    "for csv_file in os.listdir(csv_files_dir):\n",
    "    if csv_file.endswith('updated_data.csv'):\n",
    "        file_path = os.path.join(csv_files_dir, csv_file)\n",
    "        subject_number = csv_file.split('_')[0]  # Extract subject number from filename\n",
    "\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Remove rows where 'Exercise' column is empty\n",
    "        df = df.dropna(subset=['Exercise'])\n",
    "\n",
    "        # Add subject number as a new column\n",
    "        df['Subject'] = subject_number\n",
    "\n",
    "        # Append the processed DataFrame to the list\n",
    "        all_data.append(df)\n",
    "\n",
    "# Combine all data into a single DataFrame\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "combined_df.to_csv(combined_csv_file_path, index=False)\n",
    "print(f'Combined CSV file saved: {combined_csv_file_path}')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV file saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit\\combined_data_new.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directories\n",
    "csv_files_dir = 'C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit'\n",
    "output_dir = 'C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit'\n",
    "combined_csv_file_path = os.path.join(output_dir, 'combined_data_new.csv')  # New file name to avoid overwriting\n",
    "\n",
    "# List to hold data from all files\n",
    "all_data = []\n",
    "\n",
    "# Iterate through all CSV files in the directory that start with 'pat' and end with 'updated_data.csv'\n",
    "for csv_file in os.listdir(csv_files_dir):\n",
    "    if csv_file.startswith('pat') and csv_file.endswith('updated_data.csv'):\n",
    "        file_path = os.path.join(csv_files_dir, csv_file)\n",
    "        subject_number = csv_file.split('_')[0]  # Extract subject number from filename\n",
    "\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Remove rows where 'Exercise' column is empty\n",
    "        df = df.dropna(subset=['Exercise'])\n",
    "\n",
    "        # Add subject number as a new column\n",
    "        df['Subject'] = subject_number\n",
    "\n",
    "        # Append the processed DataFrame to the list\n",
    "        all_data.append(df)\n",
    "\n",
    "# Combine all data into a single DataFrame\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "combined_df.to_csv(combined_csv_file_path, index=False)\n",
    "print(f'Combined CSV file saved: {combined_csv_file_path}')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset CSV file saved: C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit/combined_data_subset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the path to the combined CSV file\n",
    "combined_csv_file_path = 'C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit/combined_data.csv'\n",
    "\n",
    "# Define the path for the subset CSV file\n",
    "subset_csv_file_path = 'C:/Users/nevio/OneDrive - ZHAW/5. Semester/Projektarbeit/combined_data_subset.csv'\n",
    "\n",
    "# Load the combined CSV file\n",
    "df = pd.read_csv(combined_csv_file_path)\n",
    "\n",
    "# Create a subset of the data (e.g., first 300 rows)\n",
    "subset_df = df.head(50)\n",
    "\n",
    "# Save the subset to a new CSV file\n",
    "subset_df.to_csv(subset_csv_file_path, index=False)\n",
    "\n",
    "print(f'Subset CSV file saved: {subset_csv_file_path}')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LPPI_AxisX  LPPI_AxisY  LPPI_AxisZ  RPPI_AxisX  RPPI_AxisY  RPPI_AxisZ  \\\n",
      "0  104.522430   32.492393  102.742126   32.939053  276.874207  279.375397   \n",
      "1  104.420219   32.387367  102.616280   32.826744  276.805817  279.185791   \n",
      "2  104.314377   32.294186  102.504173   32.720028  276.713287  279.006500   \n",
      "3  104.209587   32.190201  102.399689   32.606133  276.575317  278.810852   \n",
      "4  104.103706   32.091942  102.281235   32.498119  276.495026  278.600128   \n",
      "5  103.996223   31.991394  102.169952   32.383110  276.367462  278.399963   \n",
      "6  103.887329   31.880138  102.058784   32.261818  276.112213  278.215149   \n",
      "7  103.777580   31.776316  101.937325   32.127773  276.025757  277.945282   \n",
      "8  103.674828   31.666050  101.815521   32.008263  275.905518  277.729553   \n",
      "9  103.568069   31.551319  101.684853   31.890947  275.717194  277.599243   \n",
      "\n",
      "   LPPS_AxisX  LPPS_AxisY  LPPS_AxisZ  RPPS_AxisX  ...  RHeePoPro_AxisZ  \\\n",
      "0  263.721069  272.345917  260.211853  289.340607  ...        66.092735   \n",
      "1  263.590179  272.185791  260.183899  289.301453  ...        66.099777   \n",
      "2  263.453094  272.028931  260.140594  289.233429  ...        66.087944   \n",
      "3  263.320099  271.865204  260.104858  289.166321  ...        66.095230   \n",
      "4  263.188995  271.683533  260.071289  289.103577  ...        66.087662   \n",
      "5  263.058777  271.511383  260.034546  289.063873  ...        66.097679   \n",
      "6  262.940125  271.345551  260.001251  288.996338  ...        66.081680   \n",
      "7  262.810822  271.172089  259.967529  288.956848  ...        66.084831   \n",
      "8  262.682556  271.011932  259.932465  288.900055  ...        66.074265   \n",
      "9  262.559357  270.830200  259.899017  288.831085  ...        66.072891   \n",
      "\n",
      "   RHeeLaTer_AxisX  RHeeLaTer_AxisY  RHeeLaTer_AxisZ  RHeeMeDia_AxisX  \\\n",
      "0        29.713743        32.555149        38.157253        60.386078   \n",
      "1        29.686911        32.559536        38.525715        60.341221   \n",
      "2        29.704590        32.561855        38.500717        60.331562   \n",
      "3        29.696016        32.568684        38.130318        60.318977   \n",
      "4        29.711937        32.572662        38.101234        60.297474   \n",
      "5        29.703291        32.578640        38.453926        60.270916   \n",
      "6        29.695559        32.562881        38.071854        60.249180   \n",
      "7        29.702188        32.561787        38.050510        60.245712   \n",
      "8        29.692753        32.558960        38.036823        60.215080   \n",
      "9        29.696733        32.559551        38.023502        60.204235   \n",
      "\n",
      "   RHeeMeDia_AxisY  RHeeMeDia_AxisZ            Timestamp    Exercise  Subject  \n",
      "0        30.929983        28.538439  2021-11-16 11:06:57  Punch Left    sub01  \n",
      "1        30.904947        28.518557  2021-11-16 11:06:57  Punch Left    sub01  \n",
      "2        30.902191        28.507776  2021-11-16 11:06:57  Punch Left    sub01  \n",
      "3        30.870602        28.491241  2021-11-16 11:06:57  Punch Left    sub01  \n",
      "4        30.855612        28.474127  2021-11-16 11:06:57  Punch Left    sub01  \n",
      "5        30.837008        28.455786  2021-11-16 11:06:57  Punch Left    sub01  \n",
      "6        30.824020        29.282839  2021-11-16 11:06:57  Punch Left    sub01  \n",
      "7        30.816656        28.408621  2021-11-16 11:06:57  Punch Left    sub01  \n",
      "8        30.793497        28.398661  2021-11-16 11:06:57  Punch Left    sub01  \n",
      "9        30.772041        28.384075  2021-11-16 11:06:57  Punch Left    sub01  \n",
      "\n",
      "[10 rows x 87 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head(10))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "test"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
